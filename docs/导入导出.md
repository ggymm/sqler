# Sqler 导入导出方案设计

## 1. 设计目标

### 1.1 核心原则

1. **简单至上**：单一任务执行器，统一处理导入导出
2. **进程隔离**：任务运行在独立进程中，主进程退出后任务继续执行
3. **实时反馈**：通过标准输出流式传输进度，主进程实时展示
4. **可恢复性**：进度持久化到文件，支持断点续传和任务恢复
5. **高性能**：批量处理、流式 I/O、数据库原生接口

### 1.2 功能范围

**导入功能**：
- 支持格式：CSV、JSON、SQL
- 支持模式：替换（replace）、追加（append）、更新（update）
- 支持大文件：流式处理、分批导入、内存可控
- 支持映射：列名映射、类型转换、默认值填充

**导出功能**：
- 支持格式：CSV、JSON、SQL
- 支持筛选：WHERE 条件、指定列、排序
- 支持分片：按行数或文件大小拆分
- 支持压缩：可选 gzip 压缩

---

## 2. 整体架构

### 2.1 架构图

```
┌─────────────────────────────────────────────────────────────┐
│                    sqler-app (主进程)                         │
│                                                               │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐      │
│  │   UI 窗口     │  │  任务管理器   │  │  进度监听器   │      │
│  │  (GPUI)      │  │ TaskManager  │  │ProgressMonitor│     │
│  └──────┬───────┘  └──────┬───────┘  └──────┬───────┘      │
│         │                  │                  │              │
│         │                  │                  │              │
│    用户操作            创建任务配置       读取 stdout 解析进度  │
│         │                  │                  │              │
└─────────┼──────────────────┼──────────────────┼──────────────┘
          │                  │                  │
          │                  ▼                  ▲
          │          创建配置文件目录             │
          │     ~/.sqler/tasks/{task_id}/       │
          │                  │                  │
          │                  ▼                  │
          │          启动子进程并捕获 stdout       │
          │      Command::spawn() + pipe        │
          │                  │                  │
          └──────────────────┼──────────────────┘
                             │
                             ▼
┌─────────────────────────────────────────────────────────────┐
│              sqler-task (任务执行器子进程)                     │
│                                                               │
│  命令：sqler-task import --task-dir ~/.sqler/tasks/{id}      │
│  命令：sqler-task export --task-dir ~/.sqler/tasks/{id}      │
│                                                               │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐      │
│  │ 配置读取器    │  │ 数据处理器    │  │ 进度报告器    │      │
│  │ ConfigLoader │  │ DataProcessor │  │ ProgressReporter│   │
│  └──────┬───────┘  └──────┬───────┘  └──────┬───────┘      │
│         │                  │                  │              │
│         │                  │                  │              │
│    读取 config.json   流式处理数据      双通道输出进度       │
│         │                  │                  │              │
│         │                  │         ┌────────┴────────┐    │
│         │                  │         │                 │    │
│         │                  │         ▼                 ▼    │
│         │                  │    stdout (JSON Lines) progress.json
│         │                  │         │                 │    │
│         │                  │         │                 │    │
│         │                  ▼         │                 │    │
│         │          数据库驱动层        │                 │    │
│         │         (sqler-core)       │                 │    │
│         │                  │         │                 │    │
└─────────┼──────────────────┼─────────┼─────────────────┼────┘
          │                  │         │                 │
          │                  ▼         │                 │
          │          ┌──────────────┐  │                 │
          │          │  数据库       │  │                 │
          │          │ MySQL/PG/... │  │                 │
          │          └──────────────┘  │                 │
          │                            │                 │
          └────────────────────────────┴─────────────────┘
                    (主进程实时读取)    (持久化，支持恢复)
```

### 2.2 核心组件

#### 2.2.1 sqler-app (主进程)

**TaskManager（任务管理器）**
- 职责：
  - 生成任务 ID 和目录结构
  - 创建任务配置文件
  - 启动 sqler-task 子进程并捕获 stdout
  - 管理任务生命周期（创建、监控、取消）
- 数据结构：
  ```rust
  struct TaskHandle {
      task_id: String,
      task_dir: PathBuf,
      child: Child,                    // 子进程句柄
      stdout_reader: BufReader<ChildStdout>, // stdout 读取器
      status: TaskStatus,
      progress: Progress,
      created_at: DateTime<Utc>,
  }
  ```

**ProgressMonitor（进度监听器）**
- 职责：
  - 从子进程 stdout 读取 JSON Lines 格式的进度消息
  - 解析进度数据并更新内存状态
  - 触发 UI 更新事件
- 读取逻辑：
  ```rust
  // 非阻塞读取 stdout
  for line in stdout_reader.lines() {
      let msg: ProgressMessage = serde_json::from_str(&line)?;
      match msg.type {
          "progress" => update_ui(msg.data),
          "error" => show_error(msg.data),
          "completed" => finalize_task(msg.data),
      }
  }
  ```

**UI 窗口**
- 显示实时进度条、速度、剩余时间
- 提供暂停、取消、查看日志等操作
- 支持多任务并发显示

#### 2.2.2 sqler-task (任务执行器)

**单一可执行文件，通过子命令区分操作**：
```bash
sqler-task import --task-dir ~/.sqler/tasks/{task_id}
sqler-task export --task-dir ~/.sqler/tasks/{task_id}
```

**ConfigLoader（配置读取器）**
- 读取 `{task_dir}/config.json`
- 验证配置完整性
- 初始化数据库连接

**DataProcessor（数据处理器）**
- 导入：解析源文件 → 数据验证 → 批量写入数据库
- 导出：查询数据库 → 格式转换 → 写入目标文件
- 流式处理，内存占用恒定

**ProgressReporter（进度报告器）**
- 双通道输出：
  1. **stdout**：实时输出 JSON Lines 格式（主进程读取）
  2. **progress.json**：定期写入文件（每 1000 行或每秒）
- 输出频率：每 500ms 或每 1000 行（取决于处理速度）

---

## 3. 任务目录结构

### 3.1 目录布局

```
~/.sqler/tasks/
├── {task_id_1}/
│   ├── config.json       # 任务配置（主进程写入）
│   ├── progress.json     # 实时进度（子进程写入）
│   ├── status.json       # 任务状态（子进程写入）
│   ├── checkpoint.json   # 断点数据（子进程定期写入）
│   ├── errors.log        # 错误日志（子进程写入）
│   ├── stdout.log        # 标准输出日志（可选）
│   └── stderr.log        # 标准错误日志（可选）
├── {task_id_2}/
│   └── ...
└── templates/            # 任务模板
    ├── import-users.json
    └── export-orders.json
```

### 3.2 配置文件格式

**config.json**（主进程创建，子进程读取）
```json
{
  "task_id": "550e8400-e29b-41d4-a716-446655440000",
  "operation": "import",
  "created_at": "2025-12-20T17:00:00Z",

  "source": {
    "type": "csv",
    "path": "/path/to/users.csv",
    "encoding": "utf-8",
    "delimiter": ",",
    "has_header": true,
    "quote_char": "\""
  },

  "target": {
    "data_source": {
      "id": "datasource-uuid",
      "kind": "MySQL",
      "options": {
        "host": "127.0.0.1",
        "port": "3306",
        "username": "root",
        "password": "encrypted_password",
        "database": "test_db"
      }
    },
    "table": "users",
    "mode": "append"
  },

  "mapping": {
    "columns": {
      "姓名": "name",
      "邮箱": "email",
      "年龄": "age"
    },
    "skip_columns": ["id"],
    "default_values": {
      "created_at": "CURRENT_TIMESTAMP"
    }
  },

  "options": {
    "batch_size": 1000,
    "max_errors": 100,
    "timeout_seconds": 3600,
    "use_transaction": true,
    "checkpoint_interval": 5000
  }
}
```

**导出任务配置示例**
```json
{
  "task_id": "...",
  "operation": "export",
  "created_at": "...",

  "source": {
    "data_source": { ... },
    "table": "orders",
    "columns": ["id", "user_id", "amount", "created_at"],
    "where": "created_at >= '2025-01-01'",
    "order_by": "created_at DESC",
    "limit": 100000
  },

  "target": {
    "type": "csv",
    "path": "/path/to/orders.csv",
    "encoding": "utf-8",
    "delimiter": ",",
    "include_header": true,
    "compress": false
  },

  "options": {
    "batch_size": 1000,
    "split_by_rows": 50000,
    "timeout_seconds": 3600
  }
}
```

### 3.3 进度文件格式

**progress.json**（子进程实时更新）
```json
{
  "status": "running",
  "total_rows": 100000,
  "processed_rows": 45230,
  "success_rows": 45180,
  "error_rows": 50,
  "percentage": 45.23,
  "speed": 1520.5,
  "elapsed_seconds": 29.7,
  "estimated_seconds": 36.1,
  "last_update": "2025-12-20T17:00:29Z"
}
```

**status.json**（任务状态）
```json
{
  "status": "running",
  "pid": 12345,
  "started_at": "2025-12-20T17:00:00Z",
  "updated_at": "2025-12-20T17:00:29Z",
  "completed_at": null,
  "exit_code": null
}
```

**checkpoint.json**（断点续传）
```json
{
  "last_position": 45230,
  "last_batch_id": 45,
  "checksum": "sha256:...",
  "timestamp": "2025-12-20T17:00:29Z"
}
```

---

## 4. 进度输出协议

### 4.1 JSON Lines 格式

子进程通过 stdout 输出 JSON Lines（每行一个 JSON 对象），主进程逐行解析。

#### 4.1.1 进度更新消息

```json
{"type":"progress","data":{"processed_rows":1000,"success_rows":1000,"error_rows":0,"percentage":1.0,"speed":1500.5,"elapsed_seconds":0.67,"estimated_seconds":65.9}}
{"type":"progress","data":{"processed_rows":2000,"success_rows":2000,"error_rows":0,"percentage":2.0,"speed":1520.3,"elapsed_seconds":1.31,"estimated_seconds":64.2}}
```

#### 4.1.2 错误消息

```json
{"type":"error","data":{"severity":"warning","line":12345,"column":"email","code":"INVALID_FORMAT","message":"Invalid email format","raw_data":"john@invalid"}}
```

#### 4.1.3 状态变更消息

```json
{"type":"status","data":{"status":"running","message":"任务开始执行"}}
{"type":"status","data":{"status":"completed","message":"任务执行完成"}}
{"type":"status","data":{"status":"failed","message":"数据库连接失败","error":"Connection refused"}}
```

#### 4.1.4 完成消息

```json
{
  "type":"completed",
  "data":{
    "status":"success",
    "total_rows":100000,
    "success_rows":99950,
    "error_rows":50,
    "elapsed_seconds":65.7,
    "average_speed":1521.1,
    "error_log_path":"~/.sqler/tasks/{task_id}/errors.log"
  }
}
```

### 4.2 输出实现

**子进程端（Rust）**：
```rust
use serde_json::json;

fn report_progress(progress: &Progress) {
    let msg = json!({
        "type": "progress",
        "data": {
            "processed_rows": progress.processed_rows,
            "success_rows": progress.success_rows,
            "error_rows": progress.error_rows,
            "percentage": progress.percentage,
            "speed": progress.speed,
            "elapsed_seconds": progress.elapsed_seconds,
            "estimated_seconds": progress.estimated_seconds,
        }
    });

    // 输出到 stdout（主进程读取）
    println!("{}", msg);

    // 同时写入文件（持久化）
    write_progress_file(&progress)?;
}
```

**主进程端（Rust）**：
```rust
use std::process::{Command, Stdio};
use std::io::{BufReader, BufRead};

fn spawn_task(task_dir: &Path) -> Result<TaskHandle> {
    let mut child = Command::new("sqler-task")
        .arg("import")
        .arg("--task-dir")
        .arg(task_dir)
        .stdout(Stdio::piped())
        .stderr(Stdio::piped())
        .spawn()?;

    let stdout = child.stdout.take().unwrap();
    let reader = BufReader::new(stdout);

    // 在后台线程中读取进度
    let (tx, rx) = mpsc::channel();
    thread::spawn(move || {
        for line in reader.lines() {
            if let Ok(line) = line {
                if let Ok(msg) = serde_json::from_str::<ProgressMessage>(&line) {
                    tx.send(msg).ok();
                }
            }
        }
    });

    Ok(TaskHandle { child, progress_rx: rx, ... })
}
```

---

## 5. 任务生命周期管理

### 5.1 任务状态机

```
创建任务
   │
   ▼
┌─────────┐
│ Pending │ (配置已创建，等待启动)
└────┬────┘
     │ spawn sqler-task
     ▼
┌─────────┐
│ Running │ (子进程执行中)
└────┬────┘
     │
     ├──────────┬──────────┬──────────┐
     │          │          │          │
     ▼          ▼          ▼          ▼
Completed   Failed   Cancelled   Timeout
 (成功)     (失败)     (取消)     (超时)
```

### 5.2 任务操作流程

#### 5.2.1 创建并启动任务

```rust
// 1. 生成任务 ID 和目录
let task_id = Uuid::new_v4().to_string();
let task_dir = home_dir().join(".sqler/tasks").join(&task_id);
fs::create_dir_all(&task_dir)?;

// 2. 创建配置文件
let config = TaskConfig { ... };
fs::write(
    task_dir.join("config.json"),
    serde_json::to_string_pretty(&config)?
)?;

// 3. 启动子进程
let mut child = Command::new("sqler-task")
    .arg("import")
    .arg("--task-dir")
    .arg(&task_dir)
    .stdout(Stdio::piped())
    .stderr(Stdio::piped())
    .spawn()?;

// 4. 捕获 stdout 并创建读取器
let stdout = child.stdout.take().unwrap();
let reader = BufReader::new(stdout);

// 5. 在后台线程中持续读取进度
let (tx, rx) = mpsc::channel();
thread::spawn(move || {
    for line in reader.lines().flatten() {
        if let Ok(msg) = serde_json::from_str::<ProgressMessage>(&line) {
            tx.send(msg).ok();
        }
    }
});

// 6. 在主线程中接收进度并更新 UI
while let Ok(msg) = rx.recv() {
    match msg.type.as_str() {
        "progress" => update_progress_bar(msg.data),
        "error" => show_error_notification(msg.data),
        "completed" => finalize_task(msg.data),
        _ => {}
    }
}
```

#### 5.2.2 监控正在运行的任务

```rust
// 主进程退出后重新打开，恢复任务监控
fn recover_running_tasks() -> Vec<TaskHandle> {
    let tasks_dir = home_dir().join(".sqler/tasks");
    let mut handles = Vec::new();

    for entry in fs::read_dir(tasks_dir)? {
        let task_dir = entry?.path();
        let status_file = task_dir.join("status.json");

        if let Ok(status) = fs::read_to_string(&status_file) {
            let status: TaskStatus = serde_json::from_str(&status)?;

            // 如果任务状态是 running，检查进程是否存活
            if status.status == "running" {
                if is_process_alive(status.pid) {
                    // 进程存活，通过文件轮询恢复监控
                    handles.push(recover_task_by_polling(task_dir));
                } else {
                    // 进程已死，标记为 failed
                    mark_task_failed(&task_dir, "进程异常退出");
                }
            }
        }
    }

    handles
}

// 通过轮询进度文件恢复监控
fn recover_task_by_polling(task_dir: PathBuf) -> TaskHandle {
    let (tx, rx) = mpsc::channel();

    thread::spawn(move || {
        let progress_file = task_dir.join("progress.json");
        let mut last_mtime = SystemTime::UNIX_EPOCH;

        loop {
            if let Ok(metadata) = fs::metadata(&progress_file) {
                let mtime = metadata.modified().unwrap();
                if mtime > last_mtime {
                    last_mtime = mtime;
                    if let Ok(content) = fs::read_to_string(&progress_file) {
                        if let Ok(progress) = serde_json::from_str::<Progress>(&content) {
                            tx.send(ProgressMessage {
                                type_: "progress".into(),
                                data: progress,
                            }).ok();
                        }
                    }
                }
            }

            // 检查任务是否完成
            if let Ok(status_content) = fs::read_to_string(task_dir.join("status.json")) {
                if let Ok(status) = serde_json::from_str::<TaskStatus>(&status_content) {
                    if status.status != "running" {
                        break;
                    }
                }
            }

            thread::sleep(Duration::from_millis(500));
        }
    });

    TaskHandle { progress_rx: rx, ... }
}
```

#### 5.2.3 取消任务

```rust
fn cancel_task(task_handle: &mut TaskHandle) -> Result<()> {
    // 1. 向子进程发送 SIGTERM 信号（Unix）
    #[cfg(unix)]
    {
        use nix::sys::signal::{kill, Signal};
        use nix::unistd::Pid;

        kill(Pid::from_raw(task_handle.child.id() as i32), Signal::SIGTERM)?;
    }

    // 2. 等待子进程优雅退出（最多 5 秒）
    let timeout = Duration::from_secs(5);
    let start = Instant::now();

    while start.elapsed() < timeout {
        match task_handle.child.try_wait()? {
            Some(_) => {
                // 子进程已退出
                update_status_file(&task_handle.task_dir, "cancelled")?;
                return Ok(());
            }
            None => {
                thread::sleep(Duration::from_millis(100));
            }
        }
    }

    // 3. 超时后强制杀死进程
    task_handle.child.kill()?;
    task_handle.child.wait()?;
    update_status_file(&task_handle.task_dir, "cancelled")?;

    Ok(())
}
```

#### 5.2.4 断点续传

```rust
// 子进程启动时检查是否有检查点文件
fn load_checkpoint(task_dir: &Path) -> Option<Checkpoint> {
    let checkpoint_file = task_dir.join("checkpoint.json");
    if checkpoint_file.exists() {
        fs::read_to_string(checkpoint_file)
            .ok()
            .and_then(|s| serde_json::from_str(&s).ok())
    } else {
        None
    }
}

// 导入任务从检查点恢复
fn import_with_resume(config: &TaskConfig, checkpoint: Option<Checkpoint>) -> Result<()> {
    let start_position = checkpoint.map(|c| c.last_position).unwrap_or(0);

    let file = File::open(&config.source.path)?;
    let mut reader = BufReader::new(file);

    // 跳过已处理的行
    for _ in 0..start_position {
        let mut line = String::new();
        reader.read_line(&mut line)?;
    }

    // 从当前位置继续处理
    let mut position = start_position;
    for line in reader.lines() {
        process_row(&line?)?;
        position += 1;

        // 每 5000 行保存一次检查点
        if position % 5000 == 0 {
            save_checkpoint(&task_dir, position)?;
        }
    }

    Ok(())
}
```

---

## 6. 数据处理实现

### 6.1 导入流程

```rust
fn import_csv(config: &TaskConfig) -> Result<()> {
    // 1. 初始化数据库连接
    let mut session = create_connection(&config.target.data_source)?;

    // 2. 打开源文件
    let file = File::open(&config.source.path)?;
    let mut reader = csv::ReaderBuilder::new()
        .delimiter(config.source.delimiter.as_bytes()[0])
        .has_headers(config.source.has_header)
        .from_reader(BufReader::new(file));

    // 3. 读取表头并构建列映射
    let headers = reader.headers()?;
    let column_mapping = build_column_mapping(headers, &config.mapping)?;

    // 4. 根据导入模式处理表
    match config.target.mode.as_str() {
        "replace" => {
            session.exec(ExecReq {
                sql: format!("TRUNCATE TABLE {}", config.target.table),
                params: vec![],
            })?;
        }
        "update" => {
            // 需要主键信息，后续实现
        }
        _ => {}
    }

    // 5. 批量处理数据行
    let mut batch = Vec::with_capacity(config.options.batch_size);
    let mut stats = ImportStats::default();

    for (idx, result) in reader.records().enumerate() {
        match result {
            Ok(record) => {
                // 转换行数据
                match convert_record(&record, &column_mapping, &config.mapping) {
                    Ok(row) => {
                        batch.push(row);

                        // 批次满了，执行批量插入
                        if batch.len() >= config.options.batch_size {
                            match insert_batch(&mut session, &config.target.table, &batch) {
                                Ok(n) => {
                                    stats.success_rows += n;
                                    report_progress(&stats, idx + 1);
                                }
                                Err(e) => {
                                    stats.error_rows += batch.len();
                                    log_batch_error(&e, &batch);
                                }
                            }
                            batch.clear();
                        }
                    }
                    Err(e) => {
                        stats.error_rows += 1;
                        log_row_error(idx + 1, &e, &record);

                        // 检查是否超过错误阈值
                        if stats.error_rows > config.options.max_errors {
                            return Err(Error::TooManyErrors);
                        }
                    }
                }
            }
            Err(e) => {
                stats.error_rows += 1;
                log_parse_error(idx + 1, &e);
            }
        }

        // 定期保存检查点
        if (idx + 1) % config.options.checkpoint_interval == 0 {
            save_checkpoint(&config.task_dir, idx + 1)?;
        }
    }

    // 6. 处理剩余批次
    if !batch.is_empty() {
        insert_batch(&mut session, &config.target.table, &batch)?;
        stats.success_rows += batch.len();
    }

    // 7. 输出完成消息
    report_completed(&stats);

    Ok(())
}

fn insert_batch(
    session: &mut Box<dyn DatabaseSession>,
    table: &str,
    rows: &[HashMap<String, Value>],
) -> Result<usize> {
    // 构建批量 INSERT 语句
    let columns: Vec<_> = rows[0].keys().collect();
    let placeholders = rows.iter()
        .map(|_| format!("({})", vec!["?"; columns.len()].join(",")))
        .collect::<Vec<_>>()
        .join(",");

    let sql = format!(
        "INSERT INTO {} ({}) VALUES {}",
        table,
        columns.iter().map(|c| format!("`{}`", c)).collect::<Vec<_>>().join(","),
        placeholders
    );

    // 展平所有参数
    let mut params = Vec::new();
    for row in rows {
        for col in &columns {
            params.push(row[*col].clone());
        }
    }

    session.exec(ExecReq { sql, params })?;
    Ok(rows.len())
}
```

### 6.2 导出流程

```rust
fn export_csv(config: &TaskConfig) -> Result<()> {
    // 1. 初始化数据库连接
    let mut session = create_connection(&config.source.data_source)?;

    // 2. 构建查询 SQL
    let columns = config.source.columns.join(", ");
    let mut sql = format!("SELECT {} FROM {}", columns, config.source.table);

    if let Some(where_clause) = &config.source.where_ {
        sql.push_str(&format!(" WHERE {}", where_clause));
    }
    if let Some(order_by) = &config.source.order_by {
        sql.push_str(&format!(" ORDER BY {}", order_by));
    }
    if let Some(limit) = config.source.limit {
        sql.push_str(&format!(" LIMIT {}", limit));
    }

    // 3. 执行查询（流式获取结果）
    let resp = session.query(QueryReq {
        sql,
        params: vec![],
        paging: Paging {
            page: 1,
            page_size: config.options.batch_size,
        },
    })?;

    // 4. 创建输出文件
    let output_path = &config.target.path;
    let file = File::create(output_path)?;
    let mut writer = csv::WriterBuilder::new()
        .delimiter(config.target.delimiter.as_bytes()[0])
        .from_writer(BufWriter::new(file));

    // 5. 写入表头
    if config.target.include_header {
        writer.write_record(&config.source.columns)?;
    }

    // 6. 流式写入数据行
    let mut stats = ExportStats::default();
    let total_rows = resp.total;

    for (idx, row) in resp.data.iter().enumerate() {
        let record: Vec<String> = config.source.columns.iter()
            .map(|col| row.get(col).map(|v| v.to_string()).unwrap_or_default())
            .collect();

        writer.write_record(&record)?;
        stats.exported_rows += 1;

        // 报告进度
        if (idx + 1) % 1000 == 0 {
            report_progress(&stats, total_rows);
        }
    }

    writer.flush()?;

    // 7. 输出完成消息
    report_completed(&stats);

    Ok(())
}
```

---

## 7. 错误处理策略

### 7.1 错误分类

**致命错误（Fatal）**：
- 数据库连接失败
- 配置文件损坏
- 文件无法打开
- 内存不足
→ 立即终止任务，写入 status.json 为 "failed"

**可恢复错误（Recoverable）**：
- 单行数据格式错误
- 类型转换失败
- 唯一约束冲突
→ 记录到 errors.log，跳过该行，继续处理

**警告（Warning）**：
- 数据截断
- 使用默认值
→ 记录到 stdout，正常处理

### 7.2 错误日志格式

**errors.log**（CSV 格式）：
```csv
line,error_type,error_code,message,raw_data
12345,PARSE_ERROR,INVALID_DATE,"Invalid date '2025-13-40'","John,2025-13-40,john@example.com"
12380,CONSTRAINT_VIOLATION,DUPLICATE_KEY,"Duplicate entry '123' for key 'PRIMARY'","123,Jane,jane@example.com"
```

---

## 8. 性能优化策略

### 8.1 批量处理

- **批次大小**：默认 1000 行，根据行宽和内存自动调整
- **批量 INSERT**：单条 SQL 插入多行，减少网络往返
- **事务控制**：
  - 小文件：单事务
  - 大文件：每 10000 行一个事务

### 8.2 数据库原生接口（高级优化）

**MySQL**：
```sql
LOAD DATA LOCAL INFILE '/path/to/file.csv'
INTO TABLE users
FIELDS TERMINATED BY ',' ENCLOSED BY '"'
LINES TERMINATED BY '\n'
IGNORE 1 ROWS;
```

**PostgreSQL**：
```sql
COPY users (name, email, age)
FROM STDIN
WITH (FORMAT csv, HEADER true, DELIMITER ',');
```

**SQLite**：
```rust
// 使用事务批量插入优化
conn.execute("BEGIN TRANSACTION")?;
for batch in rows.chunks(1000) {
    // INSERT statements
}
conn.execute("COMMIT")?;
```

### 8.3 流式 I/O

- 文件读取：`BufReader` 缓冲读取，逐行解析
- 文件写入：`BufWriter` 缓冲写入，减少系统调用
- 内存占用：恒定（不随文件大小增长）

---

## 9. 用户交互设计

### 9.1 创建任务 UI

**流程**：
1. 选择操作类型（导入/导出）
2. 选择数据源
3. 选择源文件（导入）或目标表（导出）
4. 配置格式选项（分隔符、编码、模式）
5. 配置列映射（可选）
6. 预览数据（前 100 行）
7. 确认并启动

### 9.2 进度展示 UI

```
┌──────────────────────────────────────────────────┐
│ 导入任务：users.csv → test_db.users              │
├──────────────────────────────────────────────────┤
│ 状态：运行中 ● 运行时间：01:05                    │
│                                                  │
│ 进度：[████████████████░░░░] 68.4%               │
│       68,430 / 100,000 行                        │
│                                                  │
│ 速度：1,250 行/秒                                 │
│ 预计剩余：25 秒                                   │
│                                                  │
│ 统计：                                           │
│   ✓ 成功：68,380 行                              │
│   ✗ 失败：50 行                                  │
│                                                  │
│ [暂停] [取消] [查看错误日志]                      │
└──────────────────────────────────────────────────┘
```

**实现**：
```rust
// 在 GPUI 窗口中持续读取进度并更新
impl Render for ImportWindow {
    fn render(&mut self, window: &mut Window, cx: &mut Context<Self>) -> impl IntoElement {
        // 检查进度更新
        while let Ok(msg) = self.progress_rx.try_recv() {
            self.progress = msg.data;
            cx.notify();
        }

        div()
            .flex()
            .flex_col()
            .gap_4()
            .child(render_progress_bar(&self.progress))
            .child(render_statistics(&self.progress))
            .child(render_action_buttons(cx))
    }
}
```

### 9.3 任务列表 UI

显示所有任务（正在运行、已完成、失败）：

```
┌─────────────────────────────────────────────────────┐
│ 任务列表                              [刷新] [清理]  │
├─────────────────────────────────────────────────────┤
│ ● users.csv → test_db.users                         │
│   68.4% | 1,250 行/秒 | 25 秒前                     │
│   [查看详情] [取消]                                  │
├─────────────────────────────────────────────────────┤
│ ✓ orders.csv → test_db.orders                       │
│   100% | 已完成 | 5 分钟前                          │
│   [查看日志] [重新运行]                              │
├─────────────────────────────────────────────────────┤
│ ✗ products.json → test_db.products                  │
│   失败：数据库连接超时 | 10 分钟前                   │
│   [查看错误] [重试]                                  │
└─────────────────────────────────────────────────────┘
```

---

## 10. 实现路线图

### Phase 1：基础架构（Week 1-2）
- [ ] 创建 sqler-task 可执行文件项目结构
- [ ] 实现配置文件读取和验证
- [ ] 实现双通道进度输出（stdout + 文件）
- [ ] 实现主进程启动子进程并捕获 stdout
- [ ] 单元测试：配置解析、进度序列化

### Phase 2：CSV 导入导出（Week 3-4）
- [ ] 实现 CSV 解析器（支持自定义分隔符、引号）
- [ ] 实现批量 INSERT 导入逻辑
- [ ] 实现流式查询和 CSV 导出
- [ ] 实现错误处理和日志记录
- [ ] 集成测试：端到端导入导出流程

### Phase 3：UI 集成（Week 5）
- [ ] 实现任务创建 UI（表单、文件选择、预览）
- [ ] 实现进度展示 UI（进度条、统计信息）
- [ ] 实现任务列表 UI（查看所有任务）
- [ ] 实现任务控制（暂停、取消、重试）

### Phase 4：高级特性（Week 6-7）
- [ ] 实现断点续传功能
- [ ] 实现任务恢复（主进程重启后）
- [ ] 实现数据库原生接口优化（LOAD DATA、COPY）
- [ ] 实现列映射和类型转换
- [ ] 性能测试和优化

### Phase 5：扩展格式（Week 8-9）
- [ ] 实现 JSON 导入导出
- [ ] 实现 SQL 文件导入
- [ ] 实现压缩支持（gzip）
- [ ] 实现分片导出（按行数拆分）

### Phase 6：测试和文档（Week 10）
- [ ] 完整测试覆盖（单元、集成、压力测试）
- [ ] 性能基准测试
- [ ] 用户文档和示例
- [ ] Bug 修复和稳定性优化

---

## 11. 技术细节

### 11.1 子进程启动参数

```bash
# 导入任务
sqler-task import \
  --task-dir ~/.sqler/tasks/550e8400-e29b-41d4-a716-446655440000

# 导出任务
sqler-task export \
  --task-dir ~/.sqler/tasks/660f9500-f39c-52e5-b827-557766551111

# 可选参数
--log-level info              # 日志级别（debug/info/warn/error）
--no-stdout                   # 禁用 stdout 输出（仅写文件）
--checkpoint-interval 5000    # 检查点保存间隔（行数）
```

### 11.2 跨平台兼容性

**进程管理**：
- Unix/Linux/macOS：使用 `nix` crate 发送信号（SIGTERM、SIGKILL）
- Windows：使用 `windows` crate 或 `taskkill` 命令

**文件路径**：
- 统一使用 `std::path::PathBuf`
- 配置文件中路径使用绝对路径

**控制台输出**：
- UTF-8 编码
- JSON Lines 格式确保跨平台一致性

### 11.3 安全性考虑

**密码加密**：
- 配置文件中的密码字段使用 AES-256-GCM 加密
- 密钥存储在操作系统密钥链（macOS Keychain、Windows Credential Manager、Linux Secret Service）

**文件权限**：
- 任务目录权限：`0700`（仅所有者可访问）
- 配置文件权限：`0600`（仅所有者可读写）

**SQL 注入防护**：
- 使用参数化查询
- 表名、列名通过白名单验证

---

## 12. 性能目标

**基准环境**：
- CPU：4 核心
- 内存：8 GB
- 磁盘：SSD
- 数据库：本地 MySQL 8.0

**性能指标**：
- CSV 导入：>= 10,000 行/秒（小行宽，~10 列）
- CSV 导出：>= 8,000 行/秒
- 内存占用：单任务 < 512 MB（恒定）
- CPU 占用：单任务 < 80%（单核）
- 启动延迟：< 1 秒（子进程启动到开始执行）

---

## 13. 待讨论问题

### 13.1 暂停/恢复功能

**问题**：子进程如何支持暂停和恢复？

**方案 A**：通过信号
- 发送 SIGSTOP 暂停进程
- 发送 SIGCONT 恢复进程
- 问题：进程完全冻结，无法保存检查点

**方案 B**：通过文件标志
- 主进程写入 `{task_dir}/pause.flag`
- 子进程定期检查该文件，暂停时停止处理并保存检查点
- 主进程删除该文件时，子进程恢复处理

**建议**：方案 B 更可控，但增加复杂度。MVP 阶段可以不支持暂停，仅支持取消。

### 13.2 并发控制

**问题**：如何限制并发任务数量？

**方案**：
- 主进程维护任务队列
- 最大并发数：可配置（默认 2）
- 队列满时，新任务进入等待队列

---

**文档版本**: v1.0
**最后更新**: 2025-12-20
**状态**: 设计完成 - 待审阅
